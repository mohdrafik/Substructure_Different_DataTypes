{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f2af479f",
   "metadata": {},
   "outputs": [],
   "source": [
    "%run ../src/path_manager.py  # This runs the whole file once, so if AddPath() is called at the bottom of path_manager.py, \n",
    "# it will add your module path automatically.a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3c37fc2f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# from pathlib import Path\n",
    "# Normalized_data = Path.cwd().parent/\"data\"/\"normalized_npyData\"\n",
    "# import os \n",
    "\n",
    "# print(Normalized_data)\n",
    "\n",
    "# # lisspecificfiles.py\n",
    "# def readlistFiles(filepath,keyword):\n",
    "    \n",
    "#     Files = os.listdir(filepath)\n",
    "#     print(Files)\n",
    "#     for File in Files:\n",
    "#         if File.endswith(keyword):\n",
    "#             print(File)\n",
    "        \n",
    "# keyword = 'normalized.npy'\n",
    "# # readlistFiles(Normalized_data,keyword ='normalized.npy')\n",
    "# readlistFiles(Normalized_data,keyword ='Copy.txt')\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aec1a393",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import os\n",
    "# datapath =r\"E:\\Projects\\substructure_3d_data\\Substructure_Different_DataTypes\\data\\normalized_npyData\" \n",
    "# datapath = os.path.normpath(datapath)\n",
    "# print(datapath)\n",
    "# # datapath = Normalized_data\n",
    "# k1 = 'Copy.txt'\n",
    "# # k1 = 'NORMALIZED.NPY'\n",
    "# # k1 = k1.lower()\n",
    "# d1 = listmatchedFiles(datapath,k1)\n",
    "# # d1.matchedFiles()\n",
    "# print(d1.matched_Files)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0200b2d6",
   "metadata": {},
   "source": [
    "## convert the .mat data into the .npy data using the main key value from the main (.mat)  data files and saved in \"outputdatapath\".\n",
    "\n",
    "# Data/  --> Description \n",
    "- #### raw_npyData/ is directory  --> where file saved as .npy file after converting from .mat file.\n",
    "- #### normalized_matData/ is directory  --> where matNormalized data files saved as ..normalized.mat file after normalizing .mat file.\n",
    "- #### normalized_npyData/ is directory  --> where npyNormalized data files saved as -..normalized.npy file after normalizing .npy files."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e3e0b9c6",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2609ad57",
   "metadata": {},
   "outputs": [],
   "source": [
    "# calling the auxfunction \n",
    "import sys\n",
    "import os\n",
    "# # Define the module path\n",
    "# module_path = r\"E:\\Projects\\substructure_3d_data\\Substructure_Different_DataTypes\\src\\modules\"\n",
    "# if not os.path.exists(module_path):\n",
    "#     module_path = r\"C:\\Users\\Gaetano\\Desktop\\create_with_codeRafi\\MyProjects\\Substructure_Different_DataTypes\\src\\modules\"\n",
    "\n",
    "# # Add the module path to sys.path if it's not already there\n",
    "# if module_path not in sys.path:\n",
    "#     sys.path.append(module_path)\n",
    "    \n",
    "import createmat2npy as mnpy   #  this module load the .mat file,extract data according to the key and convert them into .npy file.\n",
    "datapath = r'C:\\Users\\mrafik\\OneDrive - C.N.R. STIIMA\\tomogram all data\\all_tomogram_data'\n",
    "outputdatapath = r'E:/Projects/substructure_3d_data/Substructure_Different_DataTypes/data/raw_npyData/'\n",
    "outputdatapath = os.path.normpath(outputdatapath) \n",
    "if not os.path.exists(datapath and outputdatapath):\n",
    "    datapath = r\"C:\\Users\\Gaetano\\Desktop\\create_with_codeRafi\\SharedContents\\OneDrive - C.N.R. STIIMA\\tomogram all data\\all_tomogram_data\"\n",
    "    outputdatapath = r'C:\\Users\\Gaetano\\Desktop\\create_with_codeRafi\\MyProjects\\Substructure_Different_DataTypes\\data\\raw_npyData'\n",
    "\n",
    "mnpy.mat2npy(datapath,outputdatapath)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "27129e6c-ce48-4fe6-8aae-adcbf52a8fee",
   "metadata": {},
   "source": [
    "## A function is defined to load and normalize 3D Numpy data: defined in the file createmat2npy.py file with name: load_and_normalize_npy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9152098e-4d5d-49f0-b4bd-e8c65715c315",
   "metadata": {},
   "outputs": [],
   "source": [
    "#  Python Script for Loading & Normalization \n",
    "# sys.path.append(module_path)\n",
    "# import createmat2npy as mnp"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7033a197-a0f2-4ff5-9e6e-cd617c009055",
   "metadata": {},
   "source": [
    "### all different normalized npy array data is stored in the normalized data and Dictionary saved as MATLAB .mat with name as 'all_normalizeddata.mat'\n",
    "\n",
    "- And seperatley saved the each npy file as  \"..._normalized.mat\" format also.(3d matrix format data) and also in               \"...__normalized.npy file\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c3ca96db",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set the directory containing .npy files (update this with your folder path)\n",
    "import scipy.io as sio # type: ignore\n",
    "import glob\n",
    "from pathlib import Path\n",
    "import numpy as np # type: ignore\n",
    "import createmat2npy as mnp\n",
    "import os\n",
    "\n",
    "data_folder = outputdatapath # raw_npyData/ \n",
    "\n",
    "BASE_DIR = Path.cwd().parent # where all code is there.\n",
    "\n",
    "Normalized_npyDataDir = BASE_DIR/ \"data\" / \"normalized_npyData\"\n",
    "if not os.path.exists(Normalized_npyDataDir):\n",
    "    os.makedirs(Normalized_npyDataDir)\n",
    "    print(f\"normalized npy file directory is created: {Normalized_npyDataDir}\")\n",
    "\n",
    "Normalized_matDataDir = BASE_DIR/ \"data\" / \"normalized_matData\"\n",
    "if not os.path.exists(Normalized_matDataDir):\n",
    "    os.makedirs(Normalized_matDataDir)\n",
    "    print(f\"normalized npy file directory is created: {Normalized_matDataDir}\")\n",
    "\n",
    "\n",
    "npy_files = glob.glob(os.path.join(data_folder, \"*.npy\"))  # List all .npy files\n",
    "# Dictionary to store the normalized datasets\n",
    "\n",
    "normalized_data = {}\n",
    "data_ranges = {}\n",
    "\n",
    "# Load and normalize each dataset\n",
    "for file in npy_files:\n",
    "    file_name = os.path.basename(file)\n",
    "    base_name = os.path.splitext(file_name)[0]  # Remove .npy extension\n",
    "\n",
    "    data, min_val, max_val = mnp.load_and_normalize_npy(file)  # data --> normalized data return by above function.\n",
    "    normalized_data[file_name] = data  # Store in dictionary\n",
    "    data_ranges[file_name] = (min_val, max_val)  # Store original data range\n",
    "    print(f\"Loaded and normalized {file_name} - Min: {min_val}, Max: {max_val}\")\n",
    "\n",
    "# <--------------   Save normalized data as .mat (MATLAB format) -----------> \n",
    "    mat_save_path = os.path.join(Normalized_matDataDir, f\"{base_name}_normalized.mat\")\n",
    "    sio.savemat(mat_save_path, {base_name: data})\n",
    "    print(f\" Saved file :{base_name}_normalized.mat\") #mat_save_path}\")\n",
    "    \n",
    " # <--------------  Save normalized data as .npy numpy array.-----------> \n",
    "    save_path = os.path.join(Normalized_npyDataDir,  f\"{base_name}_normalized.npy\")  # Keep same filename\n",
    "    np.save(save_path, data)\n",
    "    print(f\"Saved as npy file: {base_name}_normalized.npy | Min_val: {min_val:.4f} | Max_val: {max_val:.4f}\")\n",
    "\n",
    "data_dict_npy = normalized_data  # All different normalized npy array data is stored in the normalized data \n",
    "AllCominedData = BASE_DIR/ \"data\" / \"combined_Data\"  \n",
    "if not os.path.exists(AllCominedData):\n",
    "    os.makedirs(AllCominedData)\n",
    "    print(f\"all normalized mat file data combined and saved in this directory : {AllCominedData}\") \n",
    "#  <--------------  Save all normalized data in one dictionary and saved as.mat file --------------> \n",
    "mat_path = os.path.join(AllCominedData, \"all_normalizeddata.mat\")\n",
    "sio.savemat(mat_path, data_dict_npy)\n",
    "print(f\"Dictionary saved as MATLAB .mat: {mat_path}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c9e895fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "#  <----------- To importthe modules from src/modules/ write these lines  ----------->\n",
    "# import os\n",
    "# import sys\n",
    "# from pathlib import Path\n",
    "# from path_manager_JupyterCopy import AddPath\n",
    "# AddPath()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aa868b2a",
   "metadata": {},
   "source": [
    "###  below The code plot the histogram of normalize data "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "581ee0c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import sys\n",
    "# module_path = r\"E:\\Projects\\substructure_3d_data\\Substructure_Different_DataTypes\\src\\modules\"\n",
    "# if not os.path.exists(module_path):\n",
    "#     print(f\" i am looking for the Gaetano sys path\")\n",
    "#     module_path = r\"C:\\Users\\Gaetano\\Desktop\\create_with_codeRafi\\MyProjects\\Substructure_Different_DataTypes\\src\\modules\"\n",
    "    \n",
    "# # Add the module path to sys.path if it's nat already there\n",
    "# print(f\"module path: {module_path}\")\n",
    "# if module_path not in sys.path:\n",
    "#     sys.path.append(module_path)\n",
    "\n",
    "\n",
    "# import os\n",
    "# import sys\n",
    "# from pathlib import Path\n",
    "\n",
    "# # BASE_DIR = Path.cwd().parent\n",
    "# # SRC_DIR = Path.cwd().parent/\"src\"\n",
    "# # if str(SRC_DIR) not in sys.path:\n",
    "# #     sys.path.append(str(SRC_DIR))\n",
    "\n",
    "# # this is just for adding src/ path here so that I can call another script \n",
    "# #  src/path_manager.py which will add module path in my system path to implement here in jupyter. for calling differents modules.\n",
    "# # from addpathsrc_addpathscript import addpath \n",
    "# # addpath()\n",
    "# from path_manager_JupyterCopy import AddPath\n",
    "# AddPath()\n",
    "\n",
    "\n",
    "# from histogramplot import plot_normalizedata_hist\n",
    "# # from plot3dint import plot3dinteractive\n",
    "\n",
    "# for keyval in normalized_data:\n",
    "#     datakey = keyval\n",
    "#     print(f\"\\n data key :{datakey}\")\n",
    "#     dataval = normalized_data[datakey]\n",
    "#     voldata=dataval\n",
    "#     keyvalue = datakey\n",
    "#     # plot3dinteractive(voldata,keyvalue)\n",
    "#     plot_normalizedata_hist(dataval,datakey)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "41297bf8",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "892a6eb1",
   "metadata": {},
   "source": [
    "## Step 2: Feature Extraction & Quantile-Based Thresholding\n",
    "- Now that your 3D datasets are normalized, we will proceed with Feature Extraction & Quantile-Based Thresholding to identify meaningful substructures.\n",
    "###  Why This Step is Important?\n",
    "- Feature Extraction helps in understanding the distribution of voxel intensities.\n",
    "- Quantile-Based Thresholding helps to filter noise and identify significant regions in the dataset.\n",
    "\n",
    "## - What I Will Do?\n",
    "\n",
    "-  Step 1: Extract statistical features (mean, variance, quantiles)\n",
    "-  Step 2: Apply Quantile-Based Thresholding (0.95, 0.99 quantiles)\n",
    "-  Step 3: Visualize the thresholded regions in 3D slices\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1112a74d",
   "metadata": {},
   "outputs": [],
   "source": [
    "PROJECT_DIR = Path.cwd().parent\n",
    "PROJECT_DIR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "44aa07d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path  # type: ignore\n",
    "\n",
    "from feature_thresholding import FeatureQuantileThresholding \n",
    "from listspecificfiles import readlistFiles  \n",
    "# path to data directory make it system independent always! don't hardcore it.\n",
    "PROJECT_DIR = Path.cwd().parent\n",
    "data_dir = PROJECT_DIR/\"data\"/\"normalized_npyData\"\n",
    "save_dir = PROJECT_DIR/\"results\"/\"featureQuantileThres\"\n",
    "\n",
    "\n",
    "data_dir = r\"E:\\Projects\\substructure_3d_data\\Substructure_Different_DataTypes\\data\\normalized_npyData\"\n",
    "save_dir = r\"E:\\Projects\\substructure_3d_data\\Substructure_Different_DataTypes\\results\\featureQuantileThres\"\n",
    "cwd = Path.cwd().parent.parent\n",
    "BASE_DIR = cwd/ \"results\"\n",
    "\n",
    "fq = FeatureQuantileThresholding(data_dir, save_dir, BASE_DIR=BASE_DIR)\n",
    "fq.process(visualize=True, save_features=True)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1d0b4cea",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3fc919b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import sys\n",
    "# # from pathlib import Path\n",
    "# import os\n",
    "\n",
    "# # **Get Base Directory of Project**\n",
    "# # BASE_DIR = Path.cwd().parent  # Moves one level up from notebook directory\n",
    "# BASE_DIR = Path.cwd().parent  # Moves one level up from notebook directory\n",
    "# # BASE_DIR = Path(__file__).resolve().parent.parent  # Moves 2 levels up to project root -->  for vs code.\n",
    "\n",
    "# print(f\" Base directory :{BASE_DIR}\")\n",
    "# # **Define Correct Module Path (inside src/)**\n",
    "# MODULES_DIR = BASE_DIR / \"src\" / \"modules\"\n",
    "\n",
    "# # **Convert to string & add to sys.path**\n",
    "# sys.path.append(str(MODULES_DIR))\n",
    "\n",
    "# # **Verify path added correctly**\n",
    "# # print(\"Updated Python Path:\", sys.path)\n",
    "\n",
    "# # **Now, try importing your module**\n",
    "# from listspecificfiles import readlistFiles\n",
    "\n",
    "# print(\" Module imported successfully!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2b2f2474",
   "metadata": {},
   "outputs": [],
   "source": [
    "# from pathlib import Path\n",
    "# parent_dir = Path.cwd().parent\n",
    "# child_dir = Path.cwd().parent/ \"src\"  # here we moved to the child directory.\n",
    "# Base_dir = Path.cwd()\n",
    "# print(f\"parent_dir: {parent_dir} \\ncurrent directory: {Base_dir} \\nchild directory:{child_dir}\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "77dbf8ae",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "43562b68-ec21-46b4-82dd-343f55283d39",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dd2d8c39-21c0-4fdb-b61a-3ba49be176eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import os\n",
    "# import numpy as np\n",
    "# import plotly.graph_objects as go\n",
    "# import gc  # Garbage collector to free memory\n",
    "\n",
    "# def plot3dinteractive(voldata, keyvalue, output_dir, sample_fraction=0.005):\n",
    "#     \"\"\"Plots large 3D NumPy arrays interactively and saves as HTML.\n",
    "    \n",
    "#     - `voldata`: Input 3D NumPy array.\n",
    "#     - `keyvalue`: Filename for saving.\n",
    "#     - `output_dir`: Directory to save HTML plots.\n",
    "#     - `sample_fraction`: Fraction of points to randomly plot.\n",
    "#     \"\"\"\n",
    "#     array_3d = voldata\n",
    "#     x1, y1, z1 = array_3d.shape\n",
    "#     print(f\"Shape of {keyvalue}: {x1, y1, z1}\")\n",
    "\n",
    "#     # Create a 3D meshgrid\n",
    "#     x, y, z = np.meshgrid(np.arange(x1), np.arange(y1), np.arange(z1))\n",
    "\n",
    "#     # Mask non-zero values\n",
    "#     mask = array_3d > 0\n",
    "#     x_vals = x[mask].flatten()\n",
    "#     y_vals = y[mask].flatten()\n",
    "#     z_vals = z[mask].flatten()\n",
    "#     values = array_3d[mask].flatten()\n",
    "\n",
    "#     # **Randomly sample points** to reduce memory usage\n",
    "#     num_points = len(values)\n",
    "#     sample_size = int(num_points * sample_fraction)\n",
    "\n",
    "#     if sample_size > 0:\n",
    "#         indices = np.random.choice(num_points, sample_size, replace=False)\n",
    "#         x_vals = x_vals[indices]\n",
    "#         y_vals = y_vals[indices]\n",
    "#         z_vals = z_vals[indices]\n",
    "#         values = values[indices]\n",
    "#     else:\n",
    "#         print(f\"⚠ Warning: Not enough non-zero points for {keyvalue}. Skipping...\")\n",
    "#         return\n",
    "\n",
    "#     print(f\"Plotting {sample_size} points out of {num_points} ({sample_fraction * 100}% sampled)\")\n",
    "\n",
    "#     # **Enhanced Color Grading**\n",
    "#     colorscale = [\n",
    "#         [0.0, \"white\"],    # Outer structure (light color)\n",
    "#         [0.2, \"lightblue\"],\n",
    "#         [0.4, \"deepskyblue\"],\n",
    "#         [0.6, \"dodgerblue\"],\n",
    "#         [0.8, \"blue\"],      # Middle layers\n",
    "#         [1.0, \"darkblue\"]   # Deep inner structure (dark color)\n",
    "#     ]\n",
    "\n",
    "#     # Create a 3D scatter plot\n",
    "#     fig = go.Figure(data=go.Scatter3d(\n",
    "#         x=x_vals,\n",
    "#         y=y_vals,\n",
    "#         z=z_vals,\n",
    "#         mode='markers',\n",
    "#         marker=dict(\n",
    "#             size=2,\n",
    "#             color=values,\n",
    "#             colorscale=colorscale,\n",
    "#             opacity=0.5\n",
    "#         )\n",
    "#     ))\n",
    "\n",
    "#     # Set axis labels and layout\n",
    "#     fig.update_layout(\n",
    "#         title=f\"3D Structure: {keyvalue}\",\n",
    "#         scene=dict(\n",
    "#             xaxis_title='X',\n",
    "#             yaxis_title='Y',\n",
    "#             zaxis_title='Z',\n",
    "#             bgcolor=\"black\"  # Dark background for better contrast\n",
    "#         )\n",
    "#     )\n",
    "\n",
    "#     # **Save plot as an interactive HTML file**\n",
    "#     save_path = os.path.join(output_dir, f\"{keyvalue}.html\")\n",
    "#     fig.write_html(save_path)\n",
    "#     print(f\"✅ Saved: {save_path}\")\n",
    "\n",
    "#     # **Clear memory**\n",
    "#     del fig, x_vals, y_vals, z_vals, values\n",
    "#     gc.collect()  # Garbage collection to free memory\n",
    "\n",
    "# # **Directory paths**\n",
    "# data_dir = r\"C:\\Users\\Gaetano\\Desktop\\create_with_codeRafi\\MyProjects\\Substructure_Different_DataTypes\\data\\intermdata1\"\n",
    "# output_dir = r\"C:\\Users\\Gaetano\\Desktop\\create_with_codeRafi\\MyProjects\\Substructure_Different_DataTypes\\data\\raw\"\n",
    "\n",
    "# # **Ensure output directory exists**\n",
    "# os.makedirs(output_dir, exist_ok=True)\n",
    "\n",
    "# # **Process all .npy files one by one**\n",
    "# npy_files = [f for f in os.listdir(data_dir) if f.endswith(\".npy\")]\n",
    "\n",
    "# for filename in npy_files:\n",
    "#     file_path = os.path.join(data_dir, filename)\n",
    "#     voldata = np.load(file_path)  # Load .npy file\n",
    "#     plot3dinteractive(voldata, filename, output_dir, sample_fraction=0.05)  # Save & clear memory\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3c708c8d",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (venv)",
   "language": "python",
   "name": "venv"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
